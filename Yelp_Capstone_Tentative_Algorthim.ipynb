{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>name</th>\n",
       "      <th>categories</th>\n",
       "      <th>avg_stars</th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0aIra_B6iALlfqAriBSYA</td>\n",
       "      <td>\"Tea2go\"</td>\n",
       "      <td>Restaurants;Food;Tea Rooms;Coffee &amp; Tea</td>\n",
       "      <td>4.5</td>\n",
       "      <td>gqcbCEitsgE-3s7oAc9g-A</td>\n",
       "      <td>9oFkHW8IicDrJAuQmGYo3Q</td>\n",
       "      <td>5</td>\n",
       "      <td>2017-03-11</td>\n",
       "      <td>If you like iced tea, this is the place to go!...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0aIra_B6iALlfqAriBSYA</td>\n",
       "      <td>\"Tea2go\"</td>\n",
       "      <td>Restaurants;Food;Tea Rooms;Coffee &amp; Tea</td>\n",
       "      <td>4.5</td>\n",
       "      <td>JAJnV-A8rZZFRjTpfcGeDA</td>\n",
       "      <td>gWc0VxrzNh4qN6AuXreWGw</td>\n",
       "      <td>3</td>\n",
       "      <td>2017-09-15</td>\n",
       "      <td>My girlfriend and I had never been to the shop...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0aIra_B6iALlfqAriBSYA</td>\n",
       "      <td>\"Tea2go\"</td>\n",
       "      <td>Restaurants;Food;Tea Rooms;Coffee &amp; Tea</td>\n",
       "      <td>4.5</td>\n",
       "      <td>MFdkDjiFHADe9oLyhhFmBg</td>\n",
       "      <td>7QVNLrJDkjsDsCtODlPdsw</td>\n",
       "      <td>5</td>\n",
       "      <td>2017-12-08</td>\n",
       "      <td>Closed up shop as of yesterday.\\n\\nShelves wer...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0aIra_B6iALlfqAriBSYA</td>\n",
       "      <td>\"Tea2go\"</td>\n",
       "      <td>Restaurants;Food;Tea Rooms;Coffee &amp; Tea</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Fby1UMZdcPh2vkgBBd4uxA</td>\n",
       "      <td>v8dYMrl50FFjAiOuVNEK6A</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-07-08</td>\n",
       "      <td>Products and Service good based on previous vi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0aIra_B6iALlfqAriBSYA</td>\n",
       "      <td>\"Tea2go\"</td>\n",
       "      <td>Restaurants;Food;Tea Rooms;Coffee &amp; Tea</td>\n",
       "      <td>4.5</td>\n",
       "      <td>gfsLAtETZxsz5S_JjchUNg</td>\n",
       "      <td>qDOVAoVBObWOHAcCjsC_OA</td>\n",
       "      <td>5</td>\n",
       "      <td>2016-03-17</td>\n",
       "      <td>Really good spicy chai latte. Worker was kind ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id      name                               categories  \\\n",
       "0  -0aIra_B6iALlfqAriBSYA  \"Tea2go\"  Restaurants;Food;Tea Rooms;Coffee & Tea   \n",
       "1  -0aIra_B6iALlfqAriBSYA  \"Tea2go\"  Restaurants;Food;Tea Rooms;Coffee & Tea   \n",
       "2  -0aIra_B6iALlfqAriBSYA  \"Tea2go\"  Restaurants;Food;Tea Rooms;Coffee & Tea   \n",
       "3  -0aIra_B6iALlfqAriBSYA  \"Tea2go\"  Restaurants;Food;Tea Rooms;Coffee & Tea   \n",
       "4  -0aIra_B6iALlfqAriBSYA  \"Tea2go\"  Restaurants;Food;Tea Rooms;Coffee & Tea   \n",
       "\n",
       "   avg_stars               review_id                 user_id  stars  \\\n",
       "0        4.5  gqcbCEitsgE-3s7oAc9g-A  9oFkHW8IicDrJAuQmGYo3Q      5   \n",
       "1        4.5  JAJnV-A8rZZFRjTpfcGeDA  gWc0VxrzNh4qN6AuXreWGw      3   \n",
       "2        4.5  MFdkDjiFHADe9oLyhhFmBg  7QVNLrJDkjsDsCtODlPdsw      5   \n",
       "3        4.5  Fby1UMZdcPh2vkgBBd4uxA  v8dYMrl50FFjAiOuVNEK6A      2   \n",
       "4        4.5  gfsLAtETZxsz5S_JjchUNg  qDOVAoVBObWOHAcCjsC_OA      5   \n",
       "\n",
       "         date                                               text  useful  \\\n",
       "0  2017-03-11  If you like iced tea, this is the place to go!...       0   \n",
       "1  2017-09-15  My girlfriend and I had never been to the shop...       0   \n",
       "2  2017-12-08  Closed up shop as of yesterday.\\n\\nShelves wer...       0   \n",
       "3  2017-07-08  Products and Service good based on previous vi...       0   \n",
       "4  2016-03-17  Really good spicy chai latte. Worker was kind ...       0   \n",
       "\n",
       "   funny  cool  count  \n",
       "0      0     0     26  \n",
       "1      0     0     26  \n",
       "2      0     0     26  \n",
       "3      0     0     26  \n",
       "4      0     0     26  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv('last_2_years_restaurant_reviews.csv',nrows=10000)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Define my feature variables, here is the text of the review\n",
    "documents = df['text']\n",
    "documents.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    4415\n",
       "4    2339\n",
       "1    1192\n",
       "3    1162\n",
       "2     892\n",
       "Name: stars, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Define my target variable.predicting users' rating based on reviews. The target variable is rating.\n",
    "\n",
    "target = df['stars']\n",
    "df['stars'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create training dataset and test dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "documents_train, documents_test, target_train, target_test = \\\n",
    "train_test_split(documents, target, random_state = 1, test_size=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The younger 20 year old ish crack head looking Mexican girl with the yellow jacked up teeth and glasses absolutely cannot follow directions on orders. She has no comprehension of what \"on the side\" means and proceeded to literally put the sour cream on the side of my bowl... Some other workers here are almost as sad and bad. Why this location hires such stupidity is beyond me! But the food is standard for chipotle.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents_train.iloc[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLP representation of the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(analyzer = 'word', stop_words = 'english', \n",
    "                             lowercase = True, max_features = 5000\n",
    "                            )\n",
    "# Train the model with my training data\n",
    "documents_train_vec = vectorizer.fit_transform(documents_train).toarray()\n",
    "# Get the vocab of your tfidf\n",
    "words = vectorizer.get_feature_names()\n",
    "# Use the trained model to transform your test data\n",
    "documents_test_vec = vectorizer.transform(documents_test).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar review search engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_values(lst, n, labels):\n",
    "    #Given a list of values, find the indices with the highest n values.\n",
    "    #Return the labels for each of these indices.\n",
    "    return [labels[i] for i in np.argsort(lst)[::-1][:n]]  \n",
    "\n",
    "def get_bottom_values(lst, n, labels):\n",
    "    #Given a list of values, find the indices with the lowest n values.\n",
    "    #Return the labels for each of these indices.\n",
    "    return [labels[i] for i in np.argsort(lst)[:n]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Pleasantly surprised...the staff was very nice and attentive...but wait, you're not reading this to hear about the staff...you wanna know about the food. Its a fresh\\\\/Asian take on assembly line food...but its actually quite good. Vegetables come in a heaping serving, portions are nice and big for lunch, and even though it came with only 4 shrimps, they were.cooked to order and cooked perfectly...I plan to return.\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# Draw an arbitrary review from test (unseen in training) documents\n",
    "arbitrary_review = np.random.choice(documents_test, 1)\n",
    "arbitrary_review[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My search query: \n",
      "Pleasantly surprised...the staff was very nice and attentive...but wait, you're not reading this to hear about the staff...you wanna know about the food. Its a fresh\\/Asian take on assembly line food...but its actually quite good. Vegetables come in a heaping serving, portions are nice and big for lunch, and even though it came with only 4 shrimps, they were.cooked to order and cooked perfectly...I plan to return.\n",
      "\n",
      "Top 5 similar reviews:\n",
      "No. 1 review is Very tasty, very fresh.  I was quite surprised as I don't think much of Asian food in Phoenix, but this was good.  A little pricey for lunch I thought, but the quality of the food and service made up for it..\n",
      "\n",
      "No. 2 review is I have been coming here for many many years. Still as good as always. I love all of their food. Great gyros and chicken shawarma, falafel and everything on their menu. Cooked to order fresh ingredients and an attentive staff. Plus very inexpensive with large portions..\n",
      "\n",
      "No. 3 review is This is the best ice cream sandwich I've ever had. I came here twice in one weekend.\n",
      "\n",
      "Service is nice. Prices are fantastic. I wish I could come here more often.\n",
      "\n",
      "The chocolate chip cookies are perfectly cooked..\n",
      "\n",
      "No. 4 review is This is a great little place with good food, many vegetarian options and attentive staff..\n",
      "\n",
      "No. 5 review is Overall this place is OK if you want something really legit go to Thai basil in the Pv mall but this place is about convenience and I get that. My one biggest complaint is they have supposedly a cooked version of vegetables and a raw well the cooked is every bit as raw as the raw can you possibly cook them a little more not really into crunchy cooked vegetables.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Transform the drawn review(s) to vector(s)\n",
    "arbitrary_review_vec = vectorizer.transform([arbitrary_review[0]]).toarray()\n",
    "# Calculate the similarity score(s) between vector(s) and training vectors\n",
    "similarity_score = cosine_similarity(arbitrary_review_vec, documents_train_vec)\n",
    "\n",
    "# Let me find top 5 similar reviews\n",
    "n = 5\n",
    "similar_reviews = get_top_values(similarity_score[0], n, list(documents_train))\n",
    "\n",
    "print('My search query: \\n%s\\n' % (arbitrary_review[0]))\n",
    "print('Top %s similar reviews:' % n)\n",
    "for i in range(n):\n",
    "    print('No. %d review is %s.\\n' % (i+1, similar_reviews[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simple search engine seems working well. Its result makes sense as it will give similar positive reviews if my search query is positive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build model to predict rate based on reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Naive-Bayes Classifier\n",
    "This is the simplest model as it assumes that there is no dependence between words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "\n",
    "index = ['NaiveBayes','LogisticRegression','RandomForestClassifier','SVM','XGBoost','MLP','GradientBoostingClassifier']\n",
    "score_table = pd.DataFrame(index = index, columns= ['precision_score','recall_score','f1_score','accuracy_score'])\n",
    "\n",
    "# define function for logging the results\n",
    "def compute_log_result(algo, pred_train, pred_test):\n",
    "    \"\"\"compute and log the performance into the score_table for both training and test sets\"\"\"\n",
    "    #global precision_score,recall_score,f1_score,accuracy_score\n",
    "    # compute the performance\n",
    "    pre_score=precision_score(pred_test,pred_train, average=\"macro\")\n",
    "    rec_score=recall_score(pred_test,pred_train, average=\"macro\")\n",
    "    f1score=f1_score(pred_test,pred_train, average=\"macro\")\n",
    "    acc_score=round(accuracy_score(pred_test,pred_train)*100,2)\n",
    "    \n",
    "    # log the performance\n",
    "    score_table.loc[algo,:] = pre_score,rec_score,f1score,acc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build a Naive-Bayes Classifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf_NB = MultinomialNB()\n",
    "clf_NB.fit(documents_train_vec, target_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score for train data set is 0.580857, for test data set is: 0.530000\n"
     ]
    }
   ],
   "source": [
    "print('The accuracy score for train data set is %f, for test data set is: %f' % \\\n",
    "     (clf_NB.score(documents_train_vec, target_train), clf_NB.score(documents_test_vec, target_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Multinomial Naive Bayes:\n",
      "[[ 197    2    5   20  128]\n",
      " [  59    1    4   34  164]\n",
      " [  21    0    2   63  261]\n",
      " [   2    0    0   65  626]\n",
      " [   4    0    0   17 1325]]\n",
      "Score: 53.0\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.56      0.62       352\n",
      "           2       0.33      0.00      0.01       262\n",
      "           3       0.18      0.01      0.01       347\n",
      "           4       0.33      0.09      0.15       693\n",
      "           5       0.53      0.98      0.69      1346\n",
      "\n",
      "    accuracy                           0.53      3000\n",
      "   macro avg       0.41      0.33      0.29      3000\n",
      "weighted avg       0.44      0.53      0.42      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predmnb = clf_NB.predict(documents_test_vec)\n",
    "print(\"Confusion Matrix for Multinomial Naive Bayes:\")\n",
    "print(confusion_matrix(target_test,predmnb))\n",
    "print(\"Score:\",round(accuracy_score(target_test,predmnb)*100,2))\n",
    "print(\"Classification Report:\",classification_report(target_test,predmnb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance of Naive-Bayes Classifier is\n",
    "\n",
    "not good enough. Thus, we will try Logistic Regression Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_log_result(\"NaiveBayes\",predmnb,target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>accuracy_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NaiveBayes</th>\n",
       "      <td>0.41341</td>\n",
       "      <td>0.329487</td>\n",
       "      <td>0.294649</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingClassifier</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           precision_score recall_score  f1_score  \\\n",
       "NaiveBayes                         0.41341     0.329487  0.294649   \n",
       "LogisticRegression                     NaN          NaN       NaN   \n",
       "RandomForestClassifier                 NaN          NaN       NaN   \n",
       "SVM                                    NaN          NaN       NaN   \n",
       "XGBoost                                NaN          NaN       NaN   \n",
       "MLP                                    NaN          NaN       NaN   \n",
       "GradientBoostingClassifier             NaN          NaN       NaN   \n",
       "\n",
       "                           accuracy_score  \n",
       "NaiveBayes                             53  \n",
       "LogisticRegression                    NaN  \n",
       "RandomForestClassifier                NaN  \n",
       "SVM                                   NaN  \n",
       "XGBoost                               NaN  \n",
       "MLP                                   NaN  \n",
       "GradientBoostingClassifier            NaN  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vtani\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build a Logistic Regression Classifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf_LR = LogisticRegression()\n",
    "clf_LR.fit(documents_train_vec, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score for train data set is 0.785286, for test data set is: 0.598667\n"
     ]
    }
   ],
   "source": [
    "print('The accuracy score for train data set is %f, for test data set is: %f' % \\\n",
    "     (clf_LR.score(documents_train_vec, target_train), clf_LR.score(documents_test_vec, target_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Multinomial Naive Bayes:\n",
      "[[ 248   32   23   16   33]\n",
      " [  94   42   42   34   50]\n",
      " [  33   21   89  117   87]\n",
      " [  15    6   36  250  386]\n",
      " [  13    5    2  159 1167]]\n",
      "Score: 59.87\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.70      0.66       352\n",
      "           2       0.40      0.16      0.23       262\n",
      "           3       0.46      0.26      0.33       347\n",
      "           4       0.43      0.36      0.39       693\n",
      "           5       0.68      0.87      0.76      1346\n",
      "\n",
      "    accuracy                           0.60      3000\n",
      "   macro avg       0.52      0.47      0.47      3000\n",
      "weighted avg       0.56      0.60      0.57      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predlr = clf_LR.predict(documents_test_vec)\n",
    "print(\"Confusion Matrix for Multinomial Naive Bayes:\")\n",
    "print(confusion_matrix(target_test,predlr))\n",
    "print(\"Score:\",round(accuracy_score(target_test,predlr)*100,2))\n",
    "print(\"Classification Report:\",classification_report(target_test,predlr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared with Naive-Bayes model, Logistic Regression model improces a little bit. Let me find out the top 20 most important words given by Logistic Regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_log_result(\"LogisticRegression\",predlr,target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 words by ranking are worst, bad, horrible, terrible, money, minutes, told, manager, management, business, asked, awful, rude, disgusting, don, zero, gross, nasty, wrong, avoid.\n"
     ]
    }
   ],
   "source": [
    "# Let me find it out by ranking\n",
    "n = 20\n",
    "print ('Top 20 words by ranking are %s.' % (\", \".join(i for i in get_top_values(clf_LR.coef_[0], n, words))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top 20 important words are related with negative reviews. Why is it? I think customers may use word good, excellent to express their satisfaction for restaurants. From EDA process, we know the average rate is 3.47, which means there is no hard line to tell between average, good, perfect restaurants. However, there is a hard line (negative word) for people to comment a bad restaurants. Therefore, the negative words shows high significance in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 words for negative prediction are worst, bad, horrible, terrible, money, minutes, told, manager, management, business, asked, awful, rude, disgusting, don, zero, gross, nasty, wrong, avoid.\n"
     ]
    }
   ],
   "source": [
    "#What are the key features(words) that make the negative prediction?\n",
    "\n",
    "print ('Top 20 words for negative prediction are %s.' % (\", \".join(i for i in get_top_values(clf_LR.coef_[0], n, words))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 words for positive prediction are good, great, delicious, love, friendly, amazing, nice, best, little, bit, awesome, try, tasty, fresh, excellent, lot, pretty, really, clean, definitely.\n"
     ]
    }
   ],
   "source": [
    "#What are the key features(words) that make the positive prediction?\n",
    "\n",
    "# Let's find it out by ranking\n",
    "print ('Top 20 words for positive prediction are %s.' % (\", \".join(i for i in get_bottom_values(clf_LR.coef_[0], n, words))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance of Logistic Regression model is still not good enough. Lets Try decision tree models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Random Forest Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=25, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=5, min_samples_split=5,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=1, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build a Random Forest Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf_RF = RandomForestClassifier(n_estimators=100, max_depth = 25, min_samples_leaf= 5, \n",
    "                             min_samples_split=5, random_state = 1)\n",
    "clf_RF.fit(documents_train_vec, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score for train data set is 0.562571, for test data set is: 0.500333\n"
     ]
    }
   ],
   "source": [
    "print('The accuracy score for train data set is %f, for test data set is: %f' % \\\n",
    "     (clf_RF.score(documents_train_vec, target_train), clf_RF.score(documents_test_vec, target_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Multinomial Naive Bayes:\n",
      "[[ 135    1    1    8  207]\n",
      " [  42    0    3   12  205]\n",
      " [  19    0    6   38  284]\n",
      " [   2    0    0   34  657]\n",
      " [   8    0    0   12 1326]]\n",
      "Score: 50.03\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.38      0.48       352\n",
      "           2       0.00      0.00      0.00       262\n",
      "           3       0.60      0.02      0.03       347\n",
      "           4       0.33      0.05      0.09       693\n",
      "           5       0.49      0.99      0.66      1346\n",
      "\n",
      "    accuracy                           0.50      3000\n",
      "   macro avg       0.42      0.29      0.25      3000\n",
      "weighted avg       0.44      0.50      0.38      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predrf = clf_RF.predict(documents_test_vec)\n",
    "print(\"Confusion Matrix for Multinomial Naive Bayes:\")\n",
    "print(confusion_matrix(target_test,predrf))\n",
    "print(\"Score:\",round(accuracy_score(target_test,predrf)*100,2))\n",
    "print(\"Classification Report:\",classification_report(target_test,predrf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_log_result(\"RandomForestClassifier\",predrf,target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 words by ranking are great, amazing, good, worst, delicious, love, best, asked, ok, minutes, pretty, awesome, didn, order, favorite, fresh, told, just, friendly, wasn.\n"
     ]
    }
   ],
   "source": [
    "#What are important features (words) by inspecting the Random Forest model?\n",
    "\n",
    "n = 20\n",
    "print ('Top 20 words by ranking are %s.' % (\", \".join(i for i in get_top_values(clf_RF.feature_importances_, n, words))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random forest model performs the worst. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary:\n",
    "The object is to build a model to predict the users' rating based on users' reviews.\n",
    "I define rate (1-5 stars) as target variable and use NLP method to vectorize reviews.\n",
    "I check the rationality of NLP treatment by similarity measurement.\n",
    "I used Naive Bayes, Logistic Regression and Random Forest to build multi-target classification models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Support Vector Machines:\n",
      "[[ 264   17   18   16   37]\n",
      " [ 100   28   45   31   58]\n",
      " [  37   20   72  110  108]\n",
      " [  16    5   22  216  434]\n",
      " [  13    3    2  113 1215]]\n",
      "Score: 59.83\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.61      0.75      0.68       352\n",
      "           2       0.38      0.11      0.17       262\n",
      "           3       0.45      0.21      0.28       347\n",
      "           4       0.44      0.31      0.37       693\n",
      "           5       0.66      0.90      0.76      1346\n",
      "\n",
      "    accuracy                           0.60      3000\n",
      "   macro avg       0.51      0.46      0.45      3000\n",
      "weighted avg       0.55      0.60      0.55      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machine\n",
    "from sklearn.svm import SVC\n",
    "svm = SVC(random_state=101)\n",
    "svm.fit(documents_train_vec, target_train)\n",
    "predsvm = svm.predict(documents_test_vec)\n",
    "print(\"Confusion Matrix for Support Vector Machines:\")\n",
    "print(confusion_matrix(target_test,predsvm))\n",
    "print(\"Score:\",round(accuracy_score(target_test,predsvm)*100,2))\n",
    "print(\"Classification Report:\",classification_report(target_test,predsvm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_log_result(\"SVM\",predsvm,target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vtani\\Anaconda3\\lib\\site-packages\\dask\\config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  data = yaml.load(f.read()) or {}\n",
      "C:\\Users\\vtani\\Anaconda3\\lib\\site-packages\\distributed\\config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  defaults = yaml.load(f)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for XGBoost Classifier:\n",
      "[[ 233   37   26   29   27]\n",
      " [  79   51   49   40   43]\n",
      " [  32   29   72  133   81]\n",
      " [  19    6   52  240  376]\n",
      " [  28    6   20  169 1123]]\n",
      "Score:  57.3\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.66      0.63       352\n",
      "           2       0.40      0.19      0.26       262\n",
      "           3       0.33      0.21      0.25       347\n",
      "           4       0.39      0.35      0.37       693\n",
      "           5       0.68      0.83      0.75      1346\n",
      "\n",
      "    accuracy                           0.57      3000\n",
      "   macro avg       0.48      0.45      0.45      3000\n",
      "weighted avg       0.54      0.57      0.55      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# XGBoost Classifier\n",
    "import xgboost\n",
    "from xgboost import XGBClassifier\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(documents_train_vec, target_train)\n",
    "predxgb = xgb.predict(documents_test_vec)\n",
    "print(\"Confusion Matrix for XGBoost Classifier:\")\n",
    "print(confusion_matrix(target_test,predxgb))\n",
    "print(\"Score: \",round(accuracy_score(target_test,predxgb)*100,2))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(target_test,predxgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_log_result(\"XGBoost\",predxgb,target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Multilayer Perceptron Classifier:\n",
      "[[204  80  29  21  18]\n",
      " [ 73  78  52  35  24]\n",
      " [ 30  48  99 100  70]\n",
      " [ 15  22  74 266 316]\n",
      " [ 17  20  42 324 943]]\n",
      "Score: 53.0\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.58      0.59       352\n",
      "           2       0.31      0.30      0.31       262\n",
      "           3       0.33      0.29      0.31       347\n",
      "           4       0.36      0.38      0.37       693\n",
      "           5       0.69      0.70      0.69      1346\n",
      "\n",
      "    accuracy                           0.53      3000\n",
      "   macro avg       0.46      0.45      0.45      3000\n",
      "weighted avg       0.53      0.53      0.53      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# MULTILAYER PERCEPTRON CLASSIFIER\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier()\n",
    "mlp.fit(documents_train_vec, target_train)\n",
    "predmlp = mlp.predict(documents_test_vec)\n",
    "print(\"Confusion Matrix for Multilayer Perceptron Classifier:\")\n",
    "print(confusion_matrix(target_test,predmlp))\n",
    "print(\"Score:\",round(accuracy_score(target_test,predmlp)*100,2))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(target_test,predmlp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_log_result(\"MLP\",predmlp,target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Gradient Boosting Classifier:\n",
      "[[ 204   36   20   34   58]\n",
      " [  70   27   40   60   65]\n",
      " [  26   16   65  130  110]\n",
      " [  15    3   36  231  408]\n",
      " [  13    8    9  148 1168]]\n",
      "Score: 56.5\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.58      0.60       352\n",
      "           2       0.30      0.10      0.15       262\n",
      "           3       0.38      0.19      0.25       347\n",
      "           4       0.38      0.33      0.36       693\n",
      "           5       0.65      0.87      0.74      1346\n",
      "\n",
      "    accuracy                           0.56      3000\n",
      "   macro avg       0.47      0.41      0.42      3000\n",
      "weighted avg       0.52      0.56      0.53      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting Classifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbi = GradientBoostingClassifier(learning_rate=0.1,max_depth=5,max_features=0.5,random_state=999999)\n",
    "gbi.fit(documents_train_vec, target_train)\n",
    "predgbi = gbi.predict(documents_test_vec)\n",
    "print(\"Confusion Matrix for Gradient Boosting Classifier:\")\n",
    "print(confusion_matrix(target_test,predgbi))\n",
    "print(\"Score:\",round(accuracy_score(target_test,predgbi)*100,2))\n",
    "print(\"Classification Report:\",classification_report(target_test,predgbi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_log_result(\"GradientBoostingClassifier\",predgbi,target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>accuracy_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NaiveBayes</th>\n",
       "      <td>0.41341</td>\n",
       "      <td>0.329487</td>\n",
       "      <td>0.294649</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.517297</td>\n",
       "      <td>0.46982</td>\n",
       "      <td>0.473995</td>\n",
       "      <td>59.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.415445</td>\n",
       "      <td>0.287003</td>\n",
       "      <td>0.252337</td>\n",
       "      <td>50.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.510167</td>\n",
       "      <td>0.455745</td>\n",
       "      <td>0.450641</td>\n",
       "      <td>59.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.478686</td>\n",
       "      <td>0.448945</td>\n",
       "      <td>0.452048</td>\n",
       "      <td>57.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP</th>\n",
       "      <td>0.459027</td>\n",
       "      <td>0.449398</td>\n",
       "      <td>0.453622</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingClassifier</th>\n",
       "      <td>0.46661</td>\n",
       "      <td>0.414202</td>\n",
       "      <td>0.420351</td>\n",
       "      <td>56.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           precision_score recall_score  f1_score  \\\n",
       "NaiveBayes                         0.41341     0.329487  0.294649   \n",
       "LogisticRegression                0.517297      0.46982  0.473995   \n",
       "RandomForestClassifier            0.415445     0.287003  0.252337   \n",
       "SVM                               0.510167     0.455745  0.450641   \n",
       "XGBoost                           0.478686     0.448945  0.452048   \n",
       "MLP                               0.459027     0.449398  0.453622   \n",
       "GradientBoostingClassifier         0.46661     0.414202  0.420351   \n",
       "\n",
       "                           accuracy_score  \n",
       "NaiveBayes                             53  \n",
       "LogisticRegression                  59.87  \n",
       "RandomForestClassifier              50.03  \n",
       "SVM                                 59.83  \n",
       "XGBoost                              57.3  \n",
       "MLP                                    53  \n",
       "GradientBoostingClassifier           56.5  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
